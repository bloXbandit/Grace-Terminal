// @ts-ignore
const router = require("koa-router")();
const handleStream = require("@src/utils/stream.util");

const uuid = require("uuid");
const { sportsQueryMiddleware } = require('@src/plugins/SportsResultsHandler');
const { Op } = require('sequelize');
const Conversation = require("@src/models/Conversation");
const AgenticAgent = require("@src/agent/AgenticAgent");
const detect_intent = require("@src/agent/intent-detection");
const chat_completion = require('@src/agent/chat-completion/index')
const Message = require("@src/utils/message");
const Agent = require('@src/models/Agent')
const calcToken = require('@src/completion/calc.token.js');
const File = require('@src/models/File')
const Model = require('@src/models/Model')
const path = require('path')
const fs = require('fs').promises
const { getDirpath } = require('@src/utils/electron');
const RUNTIME_TYPE = process.env.RUNTIME_TYPE || 'local-docker'


let closeContainer
if (RUNTIME_TYPE && RUNTIME_TYPE === 'local-docker') {
  closeContainer = async () => {
    console.log('æœ¬åœ°ä¸æ‰§è¡Œ')
  }
}

const activeAgents = new Map();
// JOB QUEUE: Store pending tasks per conversation
// Map<conversation_id, Array<{ question, files, context, mode, agent_id, queuedAt }>>
const taskQueues = new Map();
const MessageTable = require('@src/models/Message');

const handle_feedback = require("@src/knowledge/feedback");
const Knowledge = require("@src/models/Knowledge");
const ENABLE_KNOWLEDGE = process.env.ENABLE_KNOWLEDGE || "ON"
const { getProfileContext } = require('@src/services/userProfile');
const { extractProfileFromMessage } = require('@src/agent/profile/extract');
const MultiAgentCoordinator = require('@src/agent/specialists/MultiAgentCoordinator');
const TaskLogger = require('@src/agent/seal/TaskLogger');
const modeCommandHandler = require('@src/agent/modes/ModeCommandHandler');
const devMode = require('@src/agent/modes/DevMode');

/**
 * @swagger
 * /api/agent/run:
 *   post:
 *     tags:
 *       - Agent
 *     summary: Execute code task and push results in real-time via SSE
 *     description: |
 *       Intelligent task execution endpoint that can automatically choose between agent mode and chat mode.
 *       - Agent mode: For complex tasks requiring code execution, file operations, or system interactions
 *       - Chat mode: For simple conversations and general Q&A
 *       - Auto mode (default): Uses AI-based intent detection to choose the appropriate mode
 *       Results are streamed in real-time via SSE.
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               question:
 *                 type: string
 *                 description: User's question or instruction
 *               conversation_id:
 *                 type: string
 *                 description: Conversation ID, used to identify the current conversation
 *               mode:
 *                 type: string
 *                 enum: [auto, agent, chat, twins]
 *                 default: auto
 *                 description: |
 *                   Execution mode:
 *                   - 'auto': Automatically choose between agent and chat based on intent detection
 *                   - 'agent': Force use agent mode for complex tasks
 *                   - 'chat': Force use chat mode for simple conversation
 *                   - 'twins': Execute both chat and agent modes in sequence
 *               fileIds:
 *                 type:json
 *             required:
 *               - question
 *     responses:
 *       200:
 *         description: æµå¼å“åº”å¼€å¯
 *         content:
 *           text/event-stream:
 *             schema:
 *               type: string
 *               description: SSE æ•°æ®æµï¼Œæ¯æ¡æ•°æ®ä¸ºä¸€ä¸ª token
 */
// Apply sports query middleware first
router.post("/run", sportsQueryMiddleware, async (ctx, next) => {
  const { request, response } = ctx;
  const body = request.body || {};
  let { question, conversation_id, fileIds, mcp_server_ids = [], model_id, agent_id, mode = 'auto' } = body;

  // Get default model if not provided
  if (!model_id) {
    const DefaultModelSetting = require('@src/models/DefaultModelSetting');
    const defaultSetting = await DefaultModelSetting.findOne({ where: { setting_type: 'assistant' } });
    model_id = defaultSetting?.model_id || 22; // Fallback to GPT-5 Pro (model 22)
  }

  await Conversation.update({ model_id, status: "running" }, { where: { conversation_id } })
  if (agent_id) {
    await Agent.update({ mcp_server_ids }, { where: { id: agent_id } })
  }
  let files = [];
  console.log("å½“å‰è¿è¡Œä»»åŠ¡ï¼š")
  const WORKSPACE_DIR = getDirpath(process.env.WORKSPACE_DIR || 'workspace', ctx.state.user.id);
  const dir_name = 'Conversation_' + conversation_id.slice(0, 6);
  const dir_path = path.join(WORKSPACE_DIR, dir_name);
  await fs.mkdir(dir_path, { recursive: true });

  // å‡†å¤‡è®°å¿†æ¨¡å—å¤„ç†é€‰é¡¹ï¼ˆä½†æ ¹æ®æ¨¡å¼ä¸åŒæ—¶æœºå¤„ç†ï¼‰
  const feedbackOptions = {
    user_feedback: question,
    conversation_id,
    agent_id,
  };

  console.log('[Agent Router] ========== FILE PROCESSING ==========');
  console.log('[Agent Router] fileIds from current message:', fileIds);
  console.log('[Agent Router] fileIds type:', typeof fileIds);
  console.log('[Agent Router] fileIds is array:', Array.isArray(fileIds));
  
  // STEP 1: Process newly uploaded files (if any) - move them to conversation folder
  if (Array.isArray(fileIds) && fileIds.length > 0) {
    console.log('[Agent Router] Processing', fileIds.length, 'newly uploaded file(s)');
    for (const fileId of fileIds) {
      await File.update(
        { conversation_id: conversation_id },
        { where: { id: fileId } }
      );
    }
    
    const newFiles = await File.findAll({
      where: { id: fileIds }
    });
    console.log('[Agent Router] New files from DB:', newFiles.length);

    // Move newly uploaded files from temp upload folder to conversation folder
    const uploadDir = path.join(WORKSPACE_DIR, 'upload');
    const targetUploadDir = path.join(dir_path, 'upload');
    await fs.mkdir(targetUploadDir, { recursive: true });

    for (const file of newFiles) {
      const srcPath = path.join(uploadDir, file.name);
      const destPath = path.join(targetUploadDir, file.name);

      try {
        await fs.rename(srcPath, destPath);
      } catch (err) {
        if (err.code === 'EXDEV' || err.code === 'EEXIST') {
          // Cross-partition or exists, copy then delete
          await fs.copyFile(srcPath, destPath);
          await fs.unlink(srcPath);
        } else {
          throw err;
        }
      }
    }
  }
  
  // STEP 2: Load ALL files for this conversation (for agent context)
  // This gives agent persistent file access across all messages
  if (conversation_id) {
    files = await File.findAll({
      where: { conversation_id: conversation_id },
      order: [['create_at', 'DESC']] // Newest first
    });
    console.log('[Agent Router] Total conversation files loaded:', files.length);
    console.log('[Agent Router] Files:', files.map(f => f.name).join(', '));
  } else {
    files = [];
    console.log('[Agent Router] No conversation_id yet, no files loaded');
  }
  if (!conversation_id) {
    conversation_id = uuid.v4();
    const title = 'Conversation_' + conversation_id.slice(0, 6);
    const newConversation = await Conversation.create({
      conversation_id: conversation_id,
      content: question,
      title: title,
      status: 'running',
      modeType: 'task',
      user_id: ctx.state.user.id,
      model_id: model_id  // Use the default model we just looked up
    });
  }

  body.responseType = body.responseType || "sse";
  const { stream, onTokenStream } = handleStream(body.responseType, response);

  // Check for mode commands (/dev, /normal, /dev status)
  const modeCommandResult = await modeCommandHandler.handleCommand(question, conversation_id);
  if (modeCommandResult) {
    // This was a mode command, return the result directly
    const content = modeCommandResult.message || modeCommandResult.error || 'Mode command executed';
    const msg = Message.format({
      status: modeCommandResult.success ? 'success' : 'failure',
      action_type: 'auto_reply',
      content: content
    });
    // Send full message object like AgenticAgent does
    onTokenStream(msg);
    // Give stream time to flush before ending
    await new Promise(resolve => setImmediate(resolve));
    await Message.saveToDB(msg, conversation_id);
    await Conversation.update({ status: 'done' }, { where: { conversation_id } });
    ctx.body = stream;
    stream.end();
    return;
  }
  // å¤„ç†æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºæ¶ˆæ¯ä¿å­˜
  for (let file of files) {
    file.filename = file.name
    file.filepath = path.join(dir_path, file.url)
  }

  const newFiles = files.map(file => {
    let obj = file.dataValues
    obj.filename = obj.name
    obj.filepath = path.join(dir_path, obj.url)
    return obj
  })

  console.log('[Agent Router] newFiles created:', newFiles.length);
  console.log('[Agent Router] newFiles:', JSON.stringify(newFiles.map(f => ({ name: f.name, filepath: f.filepath })), null, 2));

  // Get user profile context (non-invasive)
  let profileContext = '';
  try {
    profileContext = await getProfileContext(ctx.state.user.id);
  } catch (err) {
    console.error('Profile context error (non-critical):', err);
  }

  // Initialize Multi-Agent Coordinator (ONLY for Task/Auto modes)
  const coordinator = new MultiAgentCoordinator({
    conversation_id,
    user_id: ctx.state.user.id
  });

  const context = {
    onTokenStream,
    conversation_id,
    user_id: ctx.state.user.id,
    mcp_server_ids,
    agent_id,
    profileContext, // Add profile context to agent
    coordinator, // Add coordinator for specialist routing (Task/Auto modes only)
    enableSpecialistRouting: true, // Enable routing for complex tasks
    files: newFiles, // CRITICAL: Add uploaded files for file analyzer access
  }

  console.log('[Agent Router] Context created with files:', context.files ? context.files.length : 0);

  // CRITICAL FIX: Synchronous profile extraction with timeout to prevent race conditions
  try {
    await Promise.race([
      extractProfileFromMessage(ctx.state.user.id, question, conversation_id),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Profile extraction timeout')), 2000)
      )
    ]);
    console.log('[Task] Profile extraction completed successfully');
  } catch (err) {
    console.error('[Task] Profile extraction failed (continuing anyway):', err.message);
  }

  // æ ¹æ®modeå‚æ•°ç¡®å®šå¤„ç†æ–¹å¼
  let intent;
  if (mode === 'auto') {
    // CRITICAL: If files are uploaded, automatically use agent mode
    if (files && files.length > 0) {
      console.log(`[AUTO Mode] ğŸ“ File upload detected (${files.length} file(s)) - forcing agent mode`);
      intent = 'agent';
    } else {
      // è‡ªåŠ¨é€‰æ‹©ï¼šä½¿ç”¨æ„å›¾è¯†åˆ«
      console.log('è‡ªåŠ¨æ¨¡å¼ï¼šå¼€å§‹æ„å›¾è¯†åˆ«...');
      try {
        // è·å–ä¸Šä¸‹æ–‡æ¶ˆæ¯ç”¨äºæ„å›¾è¯†åˆ«
        const contextMessages = await MessageTable.findAll({
          where: {
            conversation_id: conversation_id
          },
          order: [['create_at', 'ASC']]
        })

        // æ„å»ºä¸Šä¸‹æ–‡æ ¼å¼
        const messagesContext = contextMessages.map(msg => ({
          role: msg.role,
          content: msg.content
        }));

        intent = await detect_intent(question, conversation_id, messagesContext);
        console.log('æ„å›¾è¯†åˆ«ç»“æœ:', intent);
        // å°†ç»“æœæ ‡å‡†åŒ–ä¸ºå°å†™
        intent = intent.toLowerCase().trim();
        if (intent !== 'chat' && intent !== 'agent') {
          console.log('æ„å›¾è¯†åˆ«ç»“æœå¼‚å¸¸ï¼Œé»˜è®¤ä½¿ç”¨agentæ¨¡å¼');
          intent = 'agent';
        }
      } catch (error) {
        console.error('æ„å›¾è¯†åˆ«å¤±è´¥ï¼Œé»˜è®¤ä½¿ç”¨agentæ¨¡å¼:', error);
        intent = 'agent';
      }
    }
  } else {
    // ç”¨æˆ·æŒ‡å®šæ¨¡å¼
    intent = mode.toLowerCase();
    console.log('ç”¨æˆ·æŒ‡å®šæ¨¡å¼:', intent);
    // éªŒè¯æ¨¡å¼å‚æ•°
    if (intent !== 'chat' && intent !== 'agent' && intent !== 'twins') {
      console.log('æ— æ•ˆçš„æ¨¡å¼å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨agentæ¨¡å¼');
      intent = 'agent';
    }
  }

  // æ ¹æ®æœ€ç»ˆç¡®å®šçš„æ„å›¾é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
  // å‘é€æ¨¡å¼é€šçŸ¥åˆ°å‰ç«¯
  const modeNotification = `__lemon_mode__${JSON.stringify({ mode: intent })}\n\n`;
  onTokenStream(modeNotification);

  // æå–å…¬å…±å‚æ•°
  const commonParams = {
    conversation_id, question, newFiles, feedbackOptions,
    onTokenStream, stream, context, agent_id, ctx,
    profileContext // CRITICAL: Pass profile context to all modes
  };

  // æ‰§è¡Œå¯¹åº”çš„æ¨¡å¼
  if (intent === 'chat') {
    await executeChatMode(commonParams);
  } else if (intent === 'twins') {
    await executeTwinsMode(commonParams, dir_path);
  } else {
    // Agent æ¨¡å¼ï¼šå…ˆå¤„ç†åé¦ˆï¼Œå†æ‰§è¡Œä»»åŠ¡
    console.log('ä½¿ç”¨æ™ºèƒ½ä½“æ¨¡å¼');

    // Agentæ¨¡å¼ï¼šåŒæ­¥å¤„ç†åé¦ˆï¼ˆç¡®ä¿è®°å¿†æ›´æ–°åå†æ‰§è¡Œä»»åŠ¡ï¼‰
    if (ENABLE_KNOWLEDGE === "ON") {
      try {
        await handle_feedback(feedbackOptions);
        // æ›´æ–°æ¡ç›®æ•°
        const knowledge_count = await Knowledge.count({ where: { agent_id: agent_id } });
        await Agent.update({ knowledge_count }, { where: { id: agent_id } });
        console.log('Agentæ¨¡å¼åé¦ˆå¤„ç†å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œä»»åŠ¡');
      } catch (error) {
        console.error('Agentæ¨¡å¼åé¦ˆå¤„ç†å¤±è´¥:', error);
      }
    }

    // Agentæ¨¡å¼çš„streamå…³é—­å¤„ç†ï¼ˆåŒ…å«æˆªå›¾é€»è¾‘ï¼‰
    stream.on('close', async () => {
      console.log('Agent stream closed');
      await closeContainer(ctx.state.user.id)
      // todo å®ç°æ–°çš„takeScreenshotAndUpload
      // å¦‚æœagentæœ‰åˆ¶å®šçš„replay_conversation_id,åˆ™ä¸æ›´æ–°screen_shot_url

      //æ›´æ–° Conversation çš„æˆªå›¾
      // await Conversation.update({ screen_shot_url: screen_url }, { where: { conversation_id } })

      // Check if task completed successfully and update recommend field
      await updateAgentRecommend(conversation_id, agent_id);
    });

    const onCompleted = () => {
      stream.end();
    };

    // INTERRUPTIBLE EXECUTION: Check if conversation already has active agent
    // RACE CONDITION FIX: Use atomic check-and-set to prevent duplicate executions
    const existingExecution = activeAgents.get(conversation_id);
    if (existingExecution) {
      console.log(`[Run] âš ï¸ Conversation ${conversation_id} already has active execution ${existingExecution.executionId}`);
      
      // JOB QUEUE: Add task to queue for auto-retry after current execution completes
      if (!taskQueues.has(conversation_id)) {
        taskQueues.set(conversation_id, []);
      }
      
      const queuedTask = {
        question,
        files: newFiles,
        context: { ...context }, // Clone context
        mode,
        agent_id,
        queuedAt: Date.now(),
        stream, // Keep stream reference for response
        onTokenStream
      };
      
      taskQueues.get(conversation_id).push(queuedTask);
      const queuePosition = taskQueues.get(conversation_id).length;
      
      console.log(`[Queue] Task queued for ${conversation_id}, position: ${queuePosition}`);
      
      // Send notification to user
      const notificationMsg = Message.format({
        role: 'system',
        status: 'success',
        content: `âš¡ Hold up! I'm still working on your previous request. I'll start this one right after... (Queue position: ${queuePosition})`,
        action_type: 'progress',
        task_id: conversation_id
      });
      onTokenStream(notificationMsg);
      await Message.saveToDB(notificationMsg, conversation_id);
      
      // Save queued message to DB
      const queuedMsg = Message.format({
        role: 'user',
        status: 'success',
        content: question,
        action_type: 'question',
        task_id: conversation_id,
        json: newFiles
      });
      await Message.saveToDB(queuedMsg, conversation_id);
      
      // Don't end stream yet - will be used when task executes
      return;
    }
    
    // RACE CONDITION FIX: Generate execution ID and reserve slot IMMEDIATELY
    // This prevents another request from slipping through before agent is created
    const executionId = `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const reservationTime = Date.now();
    
    // Reserve the slot with a placeholder to block concurrent requests
    activeAgents.set(conversation_id, { 
      executionId, 
      startTime: reservationTime,
      reserved: true // Marker that agent is being created
    });
    console.log(`[Run] ğŸ”’ Reserved slot ${executionId} for conversation ${conversation_id}`);
    
    // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ (æ™ºèƒ½ä½“æ¨¡å¼)
    const msg = Message.format({
      role: 'user',
      status: 'success',
      content: question,
      action_type: 'question',
      task_id: conversation_id,
      json: newFiles
    });
    const message = await Message.saveToDB(msg, conversation_id);
    // await syncQuestionVectorData(message.id,question,conversation_id)

    console.log(`[Run] Starting execution ${executionId} for conversation ${conversation_id}`);
    
    // Add execution ID to context so all messages from this run are tagged
    context.executionId = executionId;

    const agent = new AgenticAgent(context);
    // Update the reservation with the actual agent instance
    activeAgents.set(conversation_id, { agent, executionId, startTime: reservationTime });

    const startTime = Date.now();
    agent.run(question).then(async (content) => {
      console.log('content', content);
      
      // SEAL: Log successful task execution
      try {
        const conversation = await Conversation.findOne({ where: { conversation_id } });
        const execution = activeAgents.get(conversation_id);
        await TaskLogger.logTask({
          user_id: ctx.state.user?.id || 1,
          conversation_id,
          task_type: mode === 'agent' ? 'agent_task' : 'chat',
          task_description: question,
          input_data: { question, mode, files: newFiles },
          output_data: { content },
          model_used: conversation?.model_id || 'default',
          execution_time_ms: execution ? Date.now() - execution.startTime : Date.now() - startTime,
          success: true,
          tools_used: agent.toolsUsed || [],
          metadata: { agent_id, mode, executionId: execution?.executionId }
        });
      } catch (logError) {
        console.error('SEAL logging error:', logError);
      }
      
      onCompleted();
      activeAgents.delete(conversation_id);
      
      // AUTO-RETRY: Process next queued task if any
      await processNextQueuedTask(conversation_id);
    }).catch(async (error) => {
      const msg = Message.format({ status: 'success', action_type: 'error', content: error.message });
      onTokenStream(msg);
      await Message.saveToDB(msg, conversation_id);
      console.error('Agent run error:', error);
      
      // SEAL: Log failed task execution
      try {
        await TaskLogger.logTask({
          user_id: ctx.state.user?.id || 1,
          conversation_id,
          task_type: mode === 'agent' ? 'agent_task' : 'chat',
          task_description: question,
          input_data: { question, mode, files: newFiles },
          output_data: { error: error.message },
          model_used: 'default',
          execution_time_ms: Date.now() - startTime,
          success: false,
          error_message: error.message,
          tools_used: [],
          metadata: { agent_id, mode, executionId }
        });
      } catch (logError) {
        console.error('SEAL logging error:', logError);
      }
      
      onCompleted();
      activeAgents.delete(conversation_id);
      
      // AUTO-RETRY: Process next queued task if any
      await processNextQueuedTask(conversation_id);
    });
  }

  ctx.body = stream;
  ctx.status = 200;
});

/**
 * AUTO-RETRY: Process next queued task for a conversation
 */
async function processNextQueuedTask(conversation_id) {
  const queue = taskQueues.get(conversation_id);
  
  if (!queue || queue.length === 0) {
    console.log(`[Queue] No pending tasks for ${conversation_id}`);
    taskQueues.delete(conversation_id);
    return;
  }
  
  // Get next task from queue
  const nextTask = queue.shift();
  console.log(`[Queue] Processing next task for ${conversation_id}, ${queue.length} remaining`);
  
  // Send notification
  const startMsg = Message.format({
    role: 'system',
    status: 'success',
    content: `ğŸš€ Starting your queued request now...`,
    action_type: 'progress',
    task_id: conversation_id
  });
  nextTask.onTokenStream(startMsg);
  await Message.saveToDB(startMsg, conversation_id);
  
  // Execute the queued task
  try {
    // RACE CONDITION FIX: Reserve slot immediately (same pattern as main execution)
    const executionId = `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const reservationTime = Date.now();
    
    // Reserve the slot first
    activeAgents.set(conversation_id, { 
      executionId, 
      startTime: reservationTime,
      reserved: true 
    });
    console.log(`[Queue] ğŸ”’ Reserved slot ${executionId} for queued task`);
    
    nextTask.context.executionId = executionId;
    
    const agent = new AgenticAgent(nextTask.context);
    // Update reservation with actual agent
    activeAgents.set(conversation_id, { agent, executionId, startTime: reservationTime });
    
    const startTime = Date.now();
    agent.run(nextTask.question).then(async (content) => {
      console.log('[Queue] Queued task completed successfully');
      
      // Log task execution
      try {
        const conversation = await Conversation.findOne({ where: { conversation_id } });
        const execution = activeAgents.get(conversation_id);
        await TaskLogger.logTask({
          user_id: nextTask.context.user_id || 1,
          conversation_id,
          task_type: nextTask.mode === 'agent' ? 'agent_task' : 'chat',
          task_description: nextTask.question,
          input_data: { question: nextTask.question, mode: nextTask.mode, files: nextTask.files },
          output_data: { content },
          model_used: conversation?.model_id || 'default',
          execution_time_ms: execution ? Date.now() - execution.startTime : Date.now() - startTime,
          success: true,
          tools_used: agent.toolsUsed || [],
          metadata: { agent_id: nextTask.agent_id, mode: nextTask.mode, executionId: execution?.executionId, queued: true }
        });
      } catch (logError) {
        console.error('[Queue] SEAL logging error:', logError);
      }
      
      nextTask.stream.end();
      activeAgents.delete(conversation_id);
      
      // Process next task if any
      await processNextQueuedTask(conversation_id);
    }).catch(async (error) => {
      console.error('[Queue] Queued task failed:', error);
      
      const errorMsg = Message.format({ 
        status: 'success', 
        action_type: 'error', 
        content: error.message 
      });
      nextTask.onTokenStream(errorMsg);
      await Message.saveToDB(errorMsg, conversation_id);
      
      // Log failed task
      try {
        await TaskLogger.logTask({
          user_id: nextTask.context.user_id || 1,
          conversation_id,
          task_type: nextTask.mode === 'agent' ? 'agent_task' : 'chat',
          task_description: nextTask.question,
          input_data: { question: nextTask.question, mode: nextTask.mode, files: nextTask.files },
          output_data: { error: error.message },
          model_used: 'default',
          execution_time_ms: Date.now() - startTime,
          success: false,
          error_message: error.message,
          tools_used: [],
          metadata: { agent_id: nextTask.agent_id, mode: nextTask.mode, executionId, queued: true }
        });
      } catch (logError) {
        console.error('[Queue] SEAL logging error:', logError);
      }
      
      nextTask.stream.end();
      activeAgents.delete(conversation_id);
      
      // Process next task if any
      await processNextQueuedTask(conversation_id);
    });
  } catch (error) {
    console.error('[Queue] Error starting queued task:', error);
    nextTask.stream.end();
    
    // Try next task
    await processNextQueuedTask(conversation_id);
  }
}

// æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£å¸¸å®Œæˆå¹¶æ›´æ–° agent recommend å­—æ®µ
async function updateAgentRecommend(conversation_id, agent_id) {
  try {
    const agent = await Agent.findOne({ where: { id: agent_id } });
    if (!agent) {
      console.log(`Agent ${agent_id} not found`);
      return;
    }

    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨ action_type ä¸º "finish_summery" çš„æ¶ˆæ¯
    const messages = await MessageTable.findAll({
      where: {
        conversation_id: conversation_id
      }
    });

    let finishMessage = null;
    for (const message of messages) {
      try {
        let meta = message.meta;
        if (typeof meta === 'string') {
          meta = JSON.parse(meta);
        }
        console.log('meta', meta.action_type)
        if (meta && meta.action_type === 'finish_summery') {
          finishMessage = message;
          break;
        }
      } catch (error) {
        // å¿½ç•¥JSONè§£æé”™è¯¯ï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€æ¡æ¶ˆæ¯
        continue;
      }
    }

    if (finishMessage) {
      // ä»»åŠ¡æ­£å¸¸å®Œæˆï¼Œå°† recommend è®¾ä¸º 0ï¼ˆå¦‚æœä¹‹å‰æ˜¯ -1ï¼‰
      if (agent.recommend === -1) {
        await Agent.update({ recommend: 0 }, { where: { id: agent_id } });
        console.log(`Agent ${agent_id} recommend updated to 0 (task completed successfully)`);
      }
    } else {
      // ä»»åŠ¡æœªæ­£å¸¸å®Œæˆï¼Œå°† recommend è®¾ä¸º -1
      await Agent.update({ recommend: -1 }, { where: { id: agent_id } });
      console.log(`Agent ${agent_id} recommend updated to -1 (task not completed)`);
    }
  } catch (error) {
    console.error(`Error updating agent recommend for agent ${agent_id}:`, error);
  }
}

// æ‰¾åˆ°é™¤äº†todo.mdä»¥å¤–æœ€åç”Ÿæˆçš„æ–‡ä»¶
async function getFinalFile(dir_path) {
  const files = await fs.readdir(dir_path, { withFileTypes: true });
  let latestFile = null;
  let latestMtime = 0;
  let todoFile = null;

  for (const entry of files) {
    if (entry.isFile()) {
      if (entry.name === 'todo.md') {
        todoFile = path.join(dir_path, entry.name);
        continue;
      }
      const filePath = path.join(dir_path, entry.name);
      const stat = await fs.stat(filePath);
      if (stat.mtimeMs > latestMtime) {
        latestMtime = stat.mtimeMs;
        latestFile = filePath;
      }
    }
  }

  if (latestFile) {
    return latestFile;
  } else if (todoFile) {
    return todoFile;
  } else {
    // fallback: if even todo.md doesn't exist, return null
    return null;
  }
}

/**
 * @swagger
 * /api/agent/stop:
 *   post:
 *     tags:
 *       - Agent
 *     summary: åœæ­¢æ­£åœ¨æ‰§è¡Œçš„ Agent ä»»åŠ¡
 *     description: |
 *       æ¥æ”¶ä¸€ä¸ª `conversation_id` å¹¶å°è¯•åœæ­¢å¯¹åº”çš„ AgenticAgent å®ä¾‹ã€‚
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               conversation_id:
 *                 type: string
 *                 description: è¦åœæ­¢çš„ Agent çš„å¯¹è¯ ID
 *             required:
 *               - conversation_id
 *     responses:
 *       200:
 *         description: Agent æˆåŠŸåœæ­¢æˆ–æœªæ‰¾åˆ°æ´»è·ƒ Agent
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 data:
 *                   type: string
 *                 code:
 *                   type: integer
 *                   description: Status code
 *                 msg:
 *                   type: string
 *                   description: Message
 */
router.post("/stop", async ({ state, request, response }) => {
  const { conversation_id } = request.body || {};

  // INTERRUPTIBLE EXECUTION: Get execution object (contains agent, executionId, startTime)
  const execution = activeAgents.get(conversation_id);
  const agent = execution?.agent;

  await Conversation.update({ status: 'stop' }, { where: { conversation_id: conversation_id } });
  await closeContainer(state.user.id)

  // Get agent_id from conversation
  const conversation = await Conversation.findOne({ where: { conversation_id } });
  const agent_id = conversation ? conversation.agent_id : null;

  if (agent) {
    try {
      console.log(`[Stop] Stopping execution ${execution.executionId} for conversation ${conversation_id}`);
      
      if (typeof agent.stop === 'function') {
        await agent.stop();
        activeAgents.delete(conversation_id);

        // Check completion status after stop
        if (agent_id) {
          await updateAgentRecommend(conversation_id, agent_id);
        }

        response.success(`Agent execution ${execution.executionId} stopped`)
      } else {
        response.fail('Agent has no stop method')
      }
    } catch (error) {
      response.fail(`Error stopping Agent ${conversation_id}: ${error.message}`)
    }
  } else {
    response.fail(`No active agent found for conversation ${conversation_id}`)
  }
});

async function getHistoryMessageSequence(messages, pid) {
  let history_messages = []
  let current_message = messages.find(message => message.id === pid)
  history_messages.push(current_message)
  if (typeof current_message.meta === 'string') {
    current_message.meta = JSON.parse(current_message.meta);
  }
  while (!(current_message.meta.pid === -1)) {
    current_message = messages.find(message => message.id === current_message.meta.pid)
    if (typeof current_message.meta === 'string') {
      current_message.meta = JSON.parse(current_message.meta);
    }
    history_messages.push(current_message)
  }
  // reverse
  history_messages.reverse()
  return history_messages
}

// æŒ‰æ—¶é—´é¡ºåºè·å–æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼Œä¸”æ€»tokenä¸è¶…è¿‡128k
function getMessagesContextByTime(messages) {
  // æ¶ˆæ¯å·²ç»æŒ‰æ—¶é—´æ’åºï¼Œä»æœ€æ–°å¾€æ—§ç´¯åŠ tokenï¼Œè¶…è¿‡128kå°±ä¸¢å¼ƒæ›´æ—§çš„
  const reversed = messages.slice().reverse();

  let totalTokens = 0;
  const limited = [];
  for (const msg of reversed) {
    const tokens = calcToken(msg.content || "");
    if (totalTokens + tokens > 131072) break;
    limited.push(msg);
    totalTokens += tokens;
  }

  // å†åè½¬å›æ¥ï¼Œä¿æŒä»æ—§åˆ°æ–°çš„æ—¶é—´é¡ºåº
  const finalContext = limited.reverse();

  // è½¬æ¢ä¸º openai æ ‡å‡†æ ¼å¼
  return finalContext.map(msg => ({
    role: msg.role,
    content: msg.content
  }));
}

// æ‰§è¡ŒChatæ¨¡å¼
async function executeChatMode(params) {
  const { stream, conversation_id } = params;
  console.log('ä½¿ç”¨å¯¹è¯æ¨¡å¼');

  // Chatæ¨¡å¼çš„streamå…³é—­å¤„ç†ï¼ˆæ— éœ€æˆªå›¾é€»è¾‘ï¼‰
  stream.on('close', async () => {
    console.log('Chat stream closed');
  });

  await runChatPhase(params, false); // standalone chat mode
}

// æ‰§è¡ŒTwinsæ¨¡å¼
async function executeTwinsMode(params, dir_path) {
  const { question, mode, agent_id } = ctx.request.body;
  let { conversation_id, mcp_server_ids, fileIds } = ctx.request.body;
  console.log('[Agent Router] ========== NEW REQUEST ==========');
  console.log('[Agent Router] conversation_id:', conversation_id);
  console.log('[Agent Router] fileIds received:', fileIds);
  console.log('[Agent Router] question:', question);

  // Twinsæ¨¡å¼çš„streamå…³é—­å¤„ç†ï¼ˆåŒ…å«æˆªå›¾é€»è¾‘ï¼Œå› ä¸ºæœ€ç»ˆä¼šæ‰§è¡Œagentï¼‰
  stream.on('close', async () => {
    console.log('Twins stream closed');
    await closeContainer(ctx.state.user.id)
    const screen_url = ''
    const agent = await Agent.findOne({ where: { id: agent_id } })
    if (agent.replay_conversation_id == null) {
      console.log('update screen_shot_url', screen_url)
      await Agent.update({ screen_shot_url: screen_url }, { where: { id: agent_id } })
    }
    // await Conversation.update({ screen_shot_url: screen_url }, { where: { conversation_id } })
    await updateAgentRecommend(conversation_id, agent_id);
  });

  // ç¬¬ä¸€é˜¶æ®µï¼šChat
  console.log('Twinsæ¨¡å¼ - ç¬¬ä¸€é˜¶æ®µï¼šå¯¹è¯æ¨¡å¼');
  const chatModeNotification = `__lemon_mode__${JSON.stringify({ mode: 'chat', stage: 'first' })}\n\n`;
  onTokenStream(chatModeNotification);

  await runChatPhase(params, true); // twins mode
}

// é€šç”¨Chatæ‰§è¡Œå‡½æ•°
async function runChatPhase(params, isTwinsMode) {
  const { conversation_id, question, newFiles, onTokenStream, stream, agent_id, feedbackOptions, profileContext } = params;

  // å‡†å¤‡ä¸Šä¸‹æ–‡æ¶ˆæ¯
  let messagesContext = []
  const messages = await MessageTable.findAll({
    where: {
      conversation_id: conversation_id
    },
    order: [['create_at', 'ASC']]
  })

  if (messages.length > 0) {
    messagesContext = getMessagesContextByTime(messages)
  }

  // CRITICAL FIX: Use MASTER_SYSTEM_PROMPT + profileContext for consistent capabilities across all modes
  const { MASTER_SYSTEM_PROMPT } = require('@src/agent/prompt/MASTER_SYSTEM_PROMPT');
  
  // Add quick file analysis for chat mode
  let fileContext = '';
  if (newFiles && newFiles.length > 0) {
    console.log(`[Chat Mode] ğŸ“ Analyzing ${newFiles.length} uploaded file(s) for context`);
    try {
      const { analyzeFiles, generateContextSummary } = require('@src/utils/fileAnalyzer');
      // Quick analysis for chat mode (don't block if it fails)
      const analyses = await Promise.race([
        analyzeFiles(newFiles.map(f => ({ filename: f.name, filepath: f.filepath }))),
        new Promise((_, reject) => setTimeout(() => reject(new Error('File analysis timeout')), 5000))
      ]);
      if (analyses && analyses.length > 0) {
        fileContext = '\n\n' + generateContextSummary(analyses);
        console.log(`[Chat Mode] âœ… File analysis complete - added context for ${analyses.length} file(s)`);
      }
    } catch (err) {
      console.log('[Chat Mode] âš ï¸ File analysis skipped:', err.message);
    }
  }
  
  let sysPromptMessage = {
    role: 'system',
    content: `${MASTER_SYSTEM_PROMPT}

${profileContext || ''}${fileContext}`
  }
  messagesContext.unshift(sysPromptMessage)

  // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
  const userMsg = Message.format({
    role: 'user',
    status: 'success',
    content: question,
    action_type: 'chat',
    task_id: conversation_id,
    type: 'chat',
    pid: -1,
    json: newFiles
  });
  let userMessage = await Message.saveToDB(userMsg, conversation_id);
  // await syncQuestionVectorData(userMessage.id,question,conversation_id)
  let new_pid = userMessage.id

  // åˆ›å»º AbortController ç”¨äºæµæ§åˆ¶
  const abortController = new AbortController();
  activeAgents.set(conversation_id, { abort: () => abortController.abort() });

  // Chatå®Œæˆå›è°ƒ
  const onChatCompleted = async (message_id, new_pid) => {
    if (isTwinsMode) {
      // Twinsæ¨¡å¼ï¼šChatå®Œæˆåå‘é€ç»“æŸæ ‡è®°ï¼Œç„¶åæ‰§è¡ŒAgent
      const raw = `__lemon_out_end__{"message_id":"${message_id}","pid":"${new_pid}"}\n\n`;
      onTokenStream(raw);
      await runAgentPhase(params);
    } else {
      // çº¯Chatæ¨¡å¼ï¼šç»“æŸæµ
      const raw = `__lemon_out_end__{"message_id":"${message_id}","pid":"${new_pid}"}\n\n`;
      onTokenStream(raw);
      stream.end();
      await Conversation.update({ status: 'done' }, { where: { conversation_id } })
      activeAgents.delete(conversation_id);
    }

    // Chatæ¨¡å¼åé¦ˆå¤„ç†ï¼ˆå¼‚æ­¥ï¼‰
    if (ENABLE_KNOWLEDGE === "ON" && agent_id) {
      try {
        await handle_feedback(feedbackOptions);
        const knowledge_count = await Knowledge.count({ where: { agent_id: agent_id } });
        await Agent.update({ knowledge_count }, { where: { id: agent_id } });
        console.log('Chaté˜¶æ®µåé¦ˆå¤„ç†å®Œæˆ');
      } catch (error) {
        console.error('Chaté˜¶æ®µåé¦ˆå¤„ç†å¤±è´¥:', error);
      }
    }
  };

  // è°ƒç”¨å¤§æ¨¡å‹
  const options = {
    temperature: 0.7,
    messages: messagesContext,
    signal: abortController.signal
  }

  chat_completion(question, options, conversation_id, onTokenStream).then(async (content) => {
    const assistant_msg = Message.format({
      role: 'assistant',
      status: 'success',
      content: content,
      action_type: 'chat',
      task_id: conversation_id,
      type: 'chat',
      pid: new_pid
    });
    let new_message = await Message.saveToDB(assistant_msg, conversation_id);
    await onChatCompleted(new_message.id, new_pid);
  }).catch(async (error) => {
    const content = error.message
    const assistant_msg = Message.format({
      role: 'assistant',
      status: 'success',
      content: content,
      action_type: 'chat',
      task_id: conversation_id,
      type: 'chat',
      pid: new_pid
    });
    let new_message = await Message.saveToDB(assistant_msg, conversation_id);
    await onChatCompleted(new_message.id, new_pid);
  });
}

// æ‰§è¡ŒAgenté˜¶æ®µï¼ˆç”¨äºTwinsæ¨¡å¼çš„ç¬¬äºŒé˜¶æ®µï¼‰
async function runAgentPhase(params) {
  const { conversation_id, question, newFiles, onTokenStream, stream, context, agent_id, feedbackOptions } = params;

  console.log('Twinsæ¨¡å¼ - ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½ä½“æ¨¡å¼');
  const agentModeNotification = `__lemon_mode__${JSON.stringify({ mode: 'agent', stage: 'second' })}\n\n`;
  onTokenStream(agentModeNotification);

  // Agentæ¨¡å¼ï¼šåŒæ­¥å¤„ç†åé¦ˆ
  if (ENABLE_KNOWLEDGE === "ON" && agent_id) {
    try {
      await handle_feedback(feedbackOptions);
      const knowledge_count = await Knowledge.count({ where: { agent_id: agent_id } });
      await Agent.update({ knowledge_count }, { where: { id: agent_id } });
      console.log('Agenté˜¶æ®µåé¦ˆå¤„ç†å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œä»»åŠ¡');
    } catch (error) {
      console.error('Agenté˜¶æ®µåé¦ˆå¤„ç†å¤±è´¥:', error);
    }
  }

  // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ (æ™ºèƒ½ä½“æ¨¡å¼)
  const agentMsg = Message.format({
    role: 'user',
    status: 'success',
    content: question,
    action_type: 'question',
    task_id: conversation_id,
    json: newFiles
  });
  const message = await Message.saveToDB(agentMsg, conversation_id);
  // await syncQuestionVectorData(message.id,question,conversation_id)
  const agentOnCompleted = () => {
    stream.end();
  };

  const agent = new AgenticAgent(context);
  activeAgents.set(conversation_id, agent);

  agent.run(question).then(async (content) => {
    console.log('Agenté˜¶æ®µå®Œæˆ');
    agentOnCompleted();
    activeAgents.delete(conversation_id);
  }).catch(async (error) => {
    const msg = Message.format({ status: 'success', action_type: 'error', content: error.message });
    onTokenStream(msg);
    await Message.saveToDB(msg, conversation_id);
    console.error('Agenté˜¶æ®µé”™è¯¯:', error);
    agentOnCompleted();
    activeAgents.delete(conversation_id);
  });
}


module.exports = exports = router.routes();